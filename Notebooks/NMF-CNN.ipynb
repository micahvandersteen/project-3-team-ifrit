{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing recent news headline topic analysis with an existing Non-negative Matrix Factorization (NMF) model\n",
    "\n",
    "Here, we test our existing NMF topic model against a more recent batch of news headlines pulled from CNN, from April 20 - May 15, 2020.\n",
    "\n",
    "Our assumption is that the world has changed so drastically since 2016 that our existing topic model will perform poorly and a new topic model will generate entirely different categories.\n",
    "\n",
    "## Credit\n",
    "\n",
    "Parts of this work borrow from Rob Salgado's [excellent NMF tutorial](https://towardsdatascience.com/topic-modeling-articles-with-nmf-8c6b2a227a45), as well as Ravish Chawla's [NMF tutorial](https://medium.com/ml2vec/topic-modeling-is-an-unsupervised-learning-approach-to-clustering-documents-to-discover-topics-fdfbf30e27df)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/stacy/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(22)\n",
    "\n",
    "# Load the pre-trained model\n",
    "import joblib\n",
    "nmf = joblib.load('nmf_improved.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "      <th>Top1</th>\n",
       "      <th>Top2</th>\n",
       "      <th>Top3</th>\n",
       "      <th>Top4</th>\n",
       "      <th>Top5</th>\n",
       "      <th>Top6</th>\n",
       "      <th>Top7</th>\n",
       "      <th>Top8</th>\n",
       "      <th>...</th>\n",
       "      <th>Top21</th>\n",
       "      <th>Top22</th>\n",
       "      <th>Top23</th>\n",
       "      <th>Top24</th>\n",
       "      <th>Top25</th>\n",
       "      <th>combined_headlines</th>\n",
       "      <th>daily_topic_existing_lda</th>\n",
       "      <th>daily_words_existing_lda</th>\n",
       "      <th>daily_topic_new_lda</th>\n",
       "      <th>daily_words_new_lda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4/20/20</td>\n",
       "      <td>0</td>\n",
       "      <td>The US and China Want a Divorce, but Neither C...</td>\n",
       "      <td>The OnePlus 8 series is much cheaper in India ...</td>\n",
       "      <td>Facebook launches COVID-19 data maps for the U...</td>\n",
       "      <td>A guide to the NFL Draft: How to watch and wha...</td>\n",
       "      <td>How to Do Less, With Journalist Celeste Headlee</td>\n",
       "      <td>What It Will Take to Reopen Everything, Accord...</td>\n",
       "      <td>Coronavirus: Reporter challenges Trump over Cu...</td>\n",
       "      <td>Deepwater Horizon: a decade of disaster</td>\n",
       "      <td>...</td>\n",
       "      <td>Severe weather hits Southern US</td>\n",
       "      <td>Jane Goodall says COVID-19 arose from our disr...</td>\n",
       "      <td>Zoom, Skype, Microsoft Teams: Why you should c...</td>\n",
       "      <td>Facebook's interactive COVID-19 map displays s...</td>\n",
       "      <td>All the things COVID-19 will change forever, a...</td>\n",
       "      <td>The US and China Want a Divorce  but Neither C...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006*\"russian\" + 0.005*\"russia\" + 0.004*\"mill...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.015*\"launch\" + 0.012*\"want\" + 0.012*\"change\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4/21/20</td>\n",
       "      <td>0</td>\n",
       "      <td>Viruses Make Us Question What It Means to Be A...</td>\n",
       "      <td>Can You Be Happy in Quarantine?</td>\n",
       "      <td>Dr. Gupta takes virus test</td>\n",
       "      <td>How to End a Video Call Politely</td>\n",
       "      <td>The US Cities With the Worst Air Pollution All...</td>\n",
       "      <td>Marketing data platform Adverity raises $30M S...</td>\n",
       "      <td>Trump claims he will temporarily suspend immig...</td>\n",
       "      <td>What a century of fighting the flu tells us ab...</td>\n",
       "      <td>...</td>\n",
       "      <td>Telecom's Latest Dumb Claim: The Internet Only...</td>\n",
       "      <td>US hydroxychloroquine study shows no benefit t...</td>\n",
       "      <td>Razer's updated Blade Stealth gets a faster di...</td>\n",
       "      <td>The bootstrapper creates value</td>\n",
       "      <td>The bootstrapper creates value</td>\n",
       "      <td>Viruses Make Us Question What It Means to Be A...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006*\"russian\" + 0.005*\"russia\" + 0.004*\"mill...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011*\"world\" + 0.011*\"right\" + 0.011*\"time\" +...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4/22/20</td>\n",
       "      <td>1</td>\n",
       "      <td>Herd Immunity Won't Save Us</td>\n",
       "      <td>Sometimes the Best Cocktail Is a Glass of Wine</td>\n",
       "      <td>Chinese EV startup Byton furloughs hundreds in...</td>\n",
       "      <td>George Steinmetz's Bird's-Eye View of the Earth</td>\n",
       "      <td>The Deepwater Horizon Disaster Fueled a Gulf S...</td>\n",
       "      <td>Viral texts about coronavirus lockdown were am...</td>\n",
       "      <td>Facebook and Instagram test location labels to...</td>\n",
       "      <td>Is your family's chewing and slurping driving ...</td>\n",
       "      <td>...</td>\n",
       "      <td>Netflix subscribers soar like crazy as coronav...</td>\n",
       "      <td>The Latest: WHO chief hopes US will reconsider...</td>\n",
       "      <td>US failed to block UN virus vaccine resolution</td>\n",
       "      <td>TSA employees have contracted COVID-19 at 58 a...</td>\n",
       "      <td>Will There Be A Meat Shortage Because Of The C...</td>\n",
       "      <td>Herd Immunity Won t Save Us Sometimes the Best...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.005*\"israeli\" + 0.005*\"iran\" + 0.004*\"gaza\" ...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.019*\"chinese\" + 0.016*\"best\" + 0.014*\"report...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/23/20</td>\n",
       "      <td>0</td>\n",
       "      <td>‘Pokémon Journeys’ will be a Netflix exclusive...</td>\n",
       "      <td>How Argentina’s Strict Covid-19 Lockdown Saved...</td>\n",
       "      <td>Gogoro’s first e-bike is coming to the US next...</td>\n",
       "      <td>US announces millions in aid for resource-rich...</td>\n",
       "      <td>Throw us your best 60-second pitch on May 13 a...</td>\n",
       "      <td>See Fauci's testing assessment that Trump disa...</td>\n",
       "      <td>A captivating 'Mandalorian' docuseries trailer...</td>\n",
       "      <td>Don't have a desk chair? All you need is a sea...</td>\n",
       "      <td>...</td>\n",
       "      <td>These 14 charts from Goldman Sachs show how mu...</td>\n",
       "      <td>Ventilator companies are opening up critical r...</td>\n",
       "      <td>Original Content podcast: ‘Too Hot to Handle’ ...</td>\n",
       "      <td>'We can’t afford to wait': coronavirus could s...</td>\n",
       "      <td>Here’s how you can ‘reset’ your sleep cycle du...</td>\n",
       "      <td>Pokémon Journeys’ will be a Netflix exclusive...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006*\"russian\" + 0.005*\"russia\" + 0.004*\"mill...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.018*\"bank\" + 0.018*\"digital\" + 0.017*\"come\" ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4/24/20</td>\n",
       "      <td>1</td>\n",
       "      <td>Lockdown Has Taken Us From Internet Time to Gr...</td>\n",
       "      <td>Refresh Your Book Stash at a Little Free Library</td>\n",
       "      <td>Stop Travel Memories From Appearing in Your So...</td>\n",
       "      <td>If we let the US Postal Service die, we’ll be ...</td>\n",
       "      <td>30 years of Hubble telescope images</td>\n",
       "      <td>Where to Travel in an RV Right Now</td>\n",
       "      <td>Don't Inject Bleach (Sigh)</td>\n",
       "      <td>First ever 'road map' of the moon released</td>\n",
       "      <td>...</td>\n",
       "      <td>Podcast: What the heck is a 'Planetary Compute...</td>\n",
       "      <td>Dyson won't build ventilators for the UK after...</td>\n",
       "      <td>US durable goods orders slump the most since 2...</td>\n",
       "      <td>COVID-19 forced Airbnb to rethink its product ...</td>\n",
       "      <td>Coronavirus: Trump suggests injecting disinfec...</td>\n",
       "      <td>Lockdown Has Taken Us From Internet Time to Gr...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.006*\"russia\" + 0.004*\"iran\" + 0.004*\"militar...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011*\"world\" + 0.011*\"right\" + 0.011*\"time\" +...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Date  Label                                               Top1  \\\n",
       "0  4/20/20      0  The US and China Want a Divorce, but Neither C...   \n",
       "1  4/21/20      0  Viruses Make Us Question What It Means to Be A...   \n",
       "2  4/22/20      1                        Herd Immunity Won't Save Us   \n",
       "3  4/23/20      0  ‘Pokémon Journeys’ will be a Netflix exclusive...   \n",
       "4  4/24/20      1  Lockdown Has Taken Us From Internet Time to Gr...   \n",
       "\n",
       "                                                Top2  \\\n",
       "0  The OnePlus 8 series is much cheaper in India ...   \n",
       "1                    Can You Be Happy in Quarantine?   \n",
       "2     Sometimes the Best Cocktail Is a Glass of Wine   \n",
       "3  How Argentina’s Strict Covid-19 Lockdown Saved...   \n",
       "4   Refresh Your Book Stash at a Little Free Library   \n",
       "\n",
       "                                                Top3  \\\n",
       "0  Facebook launches COVID-19 data maps for the U...   \n",
       "1                         Dr. Gupta takes virus test   \n",
       "2  Chinese EV startup Byton furloughs hundreds in...   \n",
       "3  Gogoro’s first e-bike is coming to the US next...   \n",
       "4  Stop Travel Memories From Appearing in Your So...   \n",
       "\n",
       "                                                Top4  \\\n",
       "0  A guide to the NFL Draft: How to watch and wha...   \n",
       "1                   How to End a Video Call Politely   \n",
       "2    George Steinmetz's Bird's-Eye View of the Earth   \n",
       "3  US announces millions in aid for resource-rich...   \n",
       "4  If we let the US Postal Service die, we’ll be ...   \n",
       "\n",
       "                                                Top5  \\\n",
       "0    How to Do Less, With Journalist Celeste Headlee   \n",
       "1  The US Cities With the Worst Air Pollution All...   \n",
       "2  The Deepwater Horizon Disaster Fueled a Gulf S...   \n",
       "3  Throw us your best 60-second pitch on May 13 a...   \n",
       "4                30 years of Hubble telescope images   \n",
       "\n",
       "                                                Top6  \\\n",
       "0  What It Will Take to Reopen Everything, Accord...   \n",
       "1  Marketing data platform Adverity raises $30M S...   \n",
       "2  Viral texts about coronavirus lockdown were am...   \n",
       "3  See Fauci's testing assessment that Trump disa...   \n",
       "4                 Where to Travel in an RV Right Now   \n",
       "\n",
       "                                                Top7  \\\n",
       "0  Coronavirus: Reporter challenges Trump over Cu...   \n",
       "1  Trump claims he will temporarily suspend immig...   \n",
       "2  Facebook and Instagram test location labels to...   \n",
       "3  A captivating 'Mandalorian' docuseries trailer...   \n",
       "4                         Don't Inject Bleach (Sigh)   \n",
       "\n",
       "                                                Top8  ...  \\\n",
       "0            Deepwater Horizon: a decade of disaster  ...   \n",
       "1  What a century of fighting the flu tells us ab...  ...   \n",
       "2  Is your family's chewing and slurping driving ...  ...   \n",
       "3  Don't have a desk chair? All you need is a sea...  ...   \n",
       "4         First ever 'road map' of the moon released  ...   \n",
       "\n",
       "                                               Top21  \\\n",
       "0                    Severe weather hits Southern US   \n",
       "1  Telecom's Latest Dumb Claim: The Internet Only...   \n",
       "2  Netflix subscribers soar like crazy as coronav...   \n",
       "3  These 14 charts from Goldman Sachs show how mu...   \n",
       "4  Podcast: What the heck is a 'Planetary Compute...   \n",
       "\n",
       "                                               Top22  \\\n",
       "0  Jane Goodall says COVID-19 arose from our disr...   \n",
       "1  US hydroxychloroquine study shows no benefit t...   \n",
       "2  The Latest: WHO chief hopes US will reconsider...   \n",
       "3  Ventilator companies are opening up critical r...   \n",
       "4  Dyson won't build ventilators for the UK after...   \n",
       "\n",
       "                                               Top23  \\\n",
       "0  Zoom, Skype, Microsoft Teams: Why you should c...   \n",
       "1  Razer's updated Blade Stealth gets a faster di...   \n",
       "2     US failed to block UN virus vaccine resolution   \n",
       "3  Original Content podcast: ‘Too Hot to Handle’ ...   \n",
       "4  US durable goods orders slump the most since 2...   \n",
       "\n",
       "                                               Top24  \\\n",
       "0  Facebook's interactive COVID-19 map displays s...   \n",
       "1                     The bootstrapper creates value   \n",
       "2  TSA employees have contracted COVID-19 at 58 a...   \n",
       "3  'We can’t afford to wait': coronavirus could s...   \n",
       "4  COVID-19 forced Airbnb to rethink its product ...   \n",
       "\n",
       "                                               Top25  \\\n",
       "0  All the things COVID-19 will change forever, a...   \n",
       "1                     The bootstrapper creates value   \n",
       "2  Will There Be A Meat Shortage Because Of The C...   \n",
       "3  Here’s how you can ‘reset’ your sleep cycle du...   \n",
       "4  Coronavirus: Trump suggests injecting disinfec...   \n",
       "\n",
       "                                  combined_headlines daily_topic_existing_lda  \\\n",
       "0  The US and China Want a Divorce  but Neither C...                        1   \n",
       "1  Viruses Make Us Question What It Means to Be A...                        1   \n",
       "2  Herd Immunity Won t Save Us Sometimes the Best...                        6   \n",
       "3   Pokémon Journeys’ will be a Netflix exclusive...                        1   \n",
       "4  Lockdown Has Taken Us From Internet Time to Gr...                        3   \n",
       "\n",
       "                            daily_words_existing_lda daily_topic_new_lda  \\\n",
       "0  0.006*\"russian\" + 0.005*\"russia\" + 0.004*\"mill...                   8   \n",
       "1  0.006*\"russian\" + 0.005*\"russia\" + 0.004*\"mill...                   0   \n",
       "2  0.005*\"israeli\" + 0.005*\"iran\" + 0.004*\"gaza\" ...                   6   \n",
       "3  0.006*\"russian\" + 0.005*\"russia\" + 0.004*\"mill...                   1   \n",
       "4  0.006*\"russia\" + 0.004*\"iran\" + 0.004*\"militar...                   0   \n",
       "\n",
       "                                 daily_words_new_lda  \n",
       "0  0.015*\"launch\" + 0.012*\"want\" + 0.012*\"change\"...  \n",
       "1  0.011*\"world\" + 0.011*\"right\" + 0.011*\"time\" +...  \n",
       "2  0.019*\"chinese\" + 0.016*\"best\" + 0.014*\"report...  \n",
       "3  0.018*\"bank\" + 0.018*\"digital\" + 0.017*\"come\" ...  \n",
       "4  0.011*\"world\" + 0.011*\"right\" + 0.011*\"time\" +...  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data\n",
    "data = pd.read_csv(\"../Data/Combined_News_NASDAQ.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "### Lemmitize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    return WordNetLemmatizer().lemmatize(text, pos='v') # pos='v' means it peforms stemming with context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords and words shorter than 3 characters, then lemmatize\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_all_headlines = data['combined_headlines'].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the headlines using TF-IDF to create features to train our model on\n",
    "texts = cleaned_all_headlines\n",
    "dictionary = gensim.corpora.Dictionary(texts)\n",
    "\n",
    "'''\n",
    "Filter out irrelevant words:\n",
    "Keep tokens that appear in at least 15 documents\n",
    "Keep only the 100,000 most frequent tokens\n",
    "'''\n",
    "\n",
    "dictionary.filter_extremes(no_below=2, keep_n=1000)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    min_df=3, # ignore words that appear in less than 3 articles\n",
    "    max_df=0.85, # ignore words that appear in more than 85% of articles\n",
    "    max_features=5000, # limit the number of important words to 5,000\n",
    "    ngram_range=(1, 2), # look for both words and two-word phrases\n",
    "    preprocessor=' '.join # join the tokenized words instead of creating a list\n",
    ")\n",
    "\n",
    "tfidf = tfidf_vectorizer.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Array with wrong shape passed to NMF (input H). Expected (10, 229), but got (10, 5000) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-c02ffe108f7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtopic_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'daily_topic_existing_nmf'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopic_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/decomposition/_nmf.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'both'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m             \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m             shuffle=self.shuffle)\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/decomposition/_nmf.py\u001b[0m in \u001b[0;36mnon_negative_factorization\u001b[0;34m(X, W, H, n_components, init, update_H, solver, beta_loss, tol, max_iter, alpha, l1_ratio, regularization, random_state, verbose, shuffle)\u001b[0m\n\u001b[1;32m   1041\u001b[0m         \u001b[0m_check_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"NMF (input W)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mupdate_H\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m         \u001b[0m_check_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"NMF (input H)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m         \u001b[0;31m# 'mu' solver should not be initialized by zeros\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mu'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/decomposition/_nmf.py\u001b[0m in \u001b[0;36m_check_init\u001b[0;34m(A, shape, whom)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         raise ValueError('Array with wrong shape passed to %s. Expected %s, '\n\u001b[0;32m---> 56\u001b[0;31m                          'but got %s ' % (whom, shape, np.shape(A)))\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mcheck_non_negative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Array with wrong shape passed to NMF (input H). Expected (10, 229), but got (10, 5000) "
     ]
    }
   ],
   "source": [
    "topic_values = nmf.transform(tfidf)\n",
    "data['daily_topic_existing_nmf'] = topic_values.argmax(axis=1)\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41624    [portugal, raid, pension, fund, meet, deficit,...\n",
       "5620     [fearless, father, throw, suicide, bomber, sav...\n",
       "65161    [reddit, spend, morning, write, brief, history...\n",
       "72850              [vote, force, isps, disconnect, pirate]\n",
       "59075    [chvez, order, jet, intercept, military, plane...\n",
       "                               ...                        \n",
       "68615                                [england, households]\n",
       "70154              [iran, hold, american, student, prison]\n",
       "55963    [turkey, position, missiles, repulse, israeli,...\n",
       "23059    [china, moon, rover, activate, science, tool, ...\n",
       "64850         [spanish, intelligence, agents, expel, cuba]\n",
       "Name: cleaned_headlines, Length: 7361, dtype: object"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize and transform the text using TF-IDF\n",
    "Sentence here about why we use TF-IDF in this case and not BoW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the headlines using TF-IDF to create features to train our model on\n",
    "texts = train\n",
    "dictionary = gensim.corpora.Dictionary(texts)\n",
    "\n",
    "'''\n",
    "Filter out irrelevant words:\n",
    "Keep tokens that appear in at least 15 documents\n",
    "Keep only the 100,000 most frequent tokens\n",
    "'''\n",
    "dictionary.filter_extremes(no_below=15, keep_n=100000)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    min_df=3, # ignore words that appear in less than 3 articles\n",
    "    max_df=0.85, # ignore words that appear in more than 85% of articles\n",
    "    max_features=5000, # limit the number of important words to 5,000\n",
    "    ngram_range=(1, 2), # look for both words and two-word phrases\n",
    "    preprocessor=' '.join # join the tokenized words instead of creating a list\n",
    ")\n",
    "\n",
    "tfidf = tfidf_vectorizer.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and fit the NMF model on our headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init='nndsvd', l1_ratio=0.0, max_iter=200,\n",
       "    n_components=10, random_state=None, shuffle=False, solver='cd', tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create NMF model and fit it\n",
    "# We are using ten topic groupings here so it is directly comparable to the LDA model's performance\n",
    "\n",
    "'''\n",
    "\"Nonnegative Double Singular Value Decomposition (NNDSVD) is a new method designed to enhance the \n",
    "initialization stage of the nonnegative matrix factorization.\n",
    "\n",
    "\"NNDSVD is well suited to initialize NMF algorithms with sparse factors.\"\" - http://nimfa.biolab.si/nimfa.methods.seeding.nndsvd.html\n",
    "'''\n",
    "model = NMF(n_components=10, init='nndsvd')\n",
    "model.fit(tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check our NMF topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic # 1</th>\n",
       "      <th>Topic # 2</th>\n",
       "      <th>Topic # 3</th>\n",
       "      <th>Topic # 4</th>\n",
       "      <th>Topic # 5</th>\n",
       "      <th>Topic # 6</th>\n",
       "      <th>Topic # 7</th>\n",
       "      <th>Topic # 8</th>\n",
       "      <th>Topic # 9</th>\n",
       "      <th>Topic #10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>police</td>\n",
       "      <td>gaza</td>\n",
       "      <td>isis</td>\n",
       "      <td>korea</td>\n",
       "      <td>ukraine</td>\n",
       "      <td>wikileaks</td>\n",
       "      <td>say</td>\n",
       "      <td>snowden</td>\n",
       "      <td>libya</td>\n",
       "      <td>georgia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iran</td>\n",
       "      <td>israel</td>\n",
       "      <td>islamic state</td>\n",
       "      <td>north</td>\n",
       "      <td>russia</td>\n",
       "      <td>assange</td>\n",
       "      <td>china</td>\n",
       "      <td>edward</td>\n",
       "      <td>egypt</td>\n",
       "      <td>russia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kill</td>\n",
       "      <td>israeli</td>\n",
       "      <td>islamic</td>\n",
       "      <td>north korea</td>\n",
       "      <td>russian</td>\n",
       "      <td>julian</td>\n",
       "      <td>world</td>\n",
       "      <td>edward snowden</td>\n",
       "      <td>protest</td>\n",
       "      <td>ossetia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>people</td>\n",
       "      <td>hamas</td>\n",
       "      <td>ebola</td>\n",
       "      <td>south</td>\n",
       "      <td>crimea</td>\n",
       "      <td>julian assange</td>\n",
       "      <td>climate</td>\n",
       "      <td>spy</td>\n",
       "      <td>protesters</td>\n",
       "      <td>georgian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>afghanistan</td>\n",
       "      <td>palestinians</td>\n",
       "      <td>state</td>\n",
       "      <td>korean</td>\n",
       "      <td>ukrainian</td>\n",
       "      <td>cable</td>\n",
       "      <td>change</td>\n",
       "      <td>surveillance</td>\n",
       "      <td>egyptian</td>\n",
       "      <td>south ossetia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4985</th>\n",
       "      <td>gadhafi</td>\n",
       "      <td>factor</td>\n",
       "      <td>libyans</td>\n",
       "      <td>jail years</td>\n",
       "      <td>latest</td>\n",
       "      <td>mark</td>\n",
       "      <td>onion</td>\n",
       "      <td>methane</td>\n",
       "      <td>humans</td>\n",
       "      <td>sample</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4986</th>\n",
       "      <td>gaddafi</td>\n",
       "      <td>shouldn</td>\n",
       "      <td>libyan rebel</td>\n",
       "      <td>receive</td>\n",
       "      <td>later</td>\n",
       "      <td>marine</td>\n",
       "      <td>depth</td>\n",
       "      <td>mexican police</td>\n",
       "      <td>surface</td>\n",
       "      <td>samsung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4987</th>\n",
       "      <td>fukushima plant</td>\n",
       "      <td>factory</td>\n",
       "      <td>libyan</td>\n",
       "      <td>elites</td>\n",
       "      <td>lash</td>\n",
       "      <td>marijuana</td>\n",
       "      <td>omar</td>\n",
       "      <td>research</td>\n",
       "      <td>human shield</td>\n",
       "      <td>historic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4988</th>\n",
       "      <td>fukushima nuclear</td>\n",
       "      <td>shots</td>\n",
       "      <td>libya</td>\n",
       "      <td>record number</td>\n",
       "      <td>larger</td>\n",
       "      <td>marathon</td>\n",
       "      <td>describe</td>\n",
       "      <td>resistant</td>\n",
       "      <td>surveillance</td>\n",
       "      <td>hire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4989</th>\n",
       "      <td>fukushima daiichi</td>\n",
       "      <td>mideast</td>\n",
       "      <td>libel</td>\n",
       "      <td>embargo</td>\n",
       "      <td>large scale</td>\n",
       "      <td>map</td>\n",
       "      <td>deserve</td>\n",
       "      <td>mexico drug</td>\n",
       "      <td>hottest</td>\n",
       "      <td>sanctuary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4990 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Topic # 1     Topic # 2      Topic # 3      Topic # 4  \\\n",
       "0                police          gaza           isis          korea   \n",
       "1                  iran        israel  islamic state          north   \n",
       "2                  kill       israeli        islamic    north korea   \n",
       "3                people         hamas          ebola          south   \n",
       "4           afghanistan  palestinians          state         korean   \n",
       "...                 ...           ...            ...            ...   \n",
       "4985            gadhafi        factor        libyans     jail years   \n",
       "4986            gaddafi       shouldn   libyan rebel        receive   \n",
       "4987    fukushima plant       factory         libyan         elites   \n",
       "4988  fukushima nuclear         shots          libya  record number   \n",
       "4989  fukushima daiichi       mideast          libel        embargo   \n",
       "\n",
       "        Topic # 5       Topic # 6 Topic # 7       Topic # 8     Topic # 9  \\\n",
       "0         ukraine       wikileaks       say         snowden         libya   \n",
       "1          russia         assange     china          edward         egypt   \n",
       "2         russian          julian     world  edward snowden       protest   \n",
       "3          crimea  julian assange   climate             spy    protesters   \n",
       "4       ukrainian           cable    change    surveillance      egyptian   \n",
       "...           ...             ...       ...             ...           ...   \n",
       "4985       latest            mark     onion         methane        humans   \n",
       "4986        later          marine     depth  mexican police       surface   \n",
       "4987         lash       marijuana      omar        research  human shield   \n",
       "4988       larger        marathon  describe       resistant  surveillance   \n",
       "4989  large scale             map   deserve     mexico drug       hottest   \n",
       "\n",
       "          Topic #10  \n",
       "0           georgia  \n",
       "1            russia  \n",
       "2           ossetia  \n",
       "3          georgian  \n",
       "4     south ossetia  \n",
       "...             ...  \n",
       "4985         sample  \n",
       "4986        samsung  \n",
       "4987       historic  \n",
       "4988           hire  \n",
       "4989      sanctuary  \n",
       "\n",
       "[4990 rows x 10 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the topics to visually inspect them\n",
    "\n",
    "def get_nmf_topics(model, n_top_words):\n",
    "    \n",
    "    #the word ids obtained need to be reverse-mapped to the words so we can print the topic names.\n",
    "    feat_names = tfidf_vectorizer.get_feature_names()\n",
    "    \n",
    "    word_dict = {};\n",
    "    for i in range(10):\n",
    "        \n",
    "        #for each topic, obtain the largest values, and add the words they map to into the dictionary.\n",
    "        words_ids = model.components_[i].argsort()[:10 - 1:-1]\n",
    "        words = [feat_names[key] for key in words_ids]\n",
    "        word_dict['Topic #' + '{:2d}'.format(i+1)] = words\n",
    "    \n",
    "    return pd.DataFrame(word_dict)\n",
    "\n",
    "get_nmf_topics(model, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, these topics seem to be a lot more coherent than what the LDA model produced. There's not only better in-topic coherence (i.e. the words relate to each other well) but also distinctions between topics (i.e. there's less keyword overlap from topic to topic).\n",
    "\n",
    "## Testing the model on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>pred_topic_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[portugal, raid, pension, fund, meet, deficit,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[fearless, father, throw, suicide, bomber, sav...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[reddit, spend, morning, write, brief, history...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[vote, force, isps, disconnect, pirate]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[chvez, order, jet, intercept, military, plane...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                test  pred_topic_num\n",
       "0  [portugal, raid, pension, fund, meet, deficit,...               1\n",
       "1  [fearless, father, throw, suicide, bomber, sav...               4\n",
       "2  [reddit, spend, morning, write, brief, history...               1\n",
       "3            [vote, force, isps, disconnect, pirate]               1\n",
       "4  [chvez, order, jet, intercept, military, plane...               5"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackabuse.com/python-for-nlp-topic-modeling/\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# See how well our model performed by using the test data\n",
    "tfidf_test = tfidf_vectorizer.transform(test)\n",
    "X_test = model.transform(tfidf_test)\n",
    "\n",
    "# Get the top predicted topic\n",
    "predicted_topics = [np.argsort(each)[::-1][0] + 1 for each in X_test]    \n",
    "\n",
    "# Add to the df\n",
    "df['test'] = test\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df['pred_topic_num'] = predicted_topics\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find a single topic per day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting the headlines into topics isn't working so well against the test data. Maybe more topics are better? This is where a **coherence score** would come in: it is a score that tells you how \"coherent\" (closely related) the words within a topic are, and you can use it to [automatically select the best number of topics](https://towardsdatascience.com/topic-modeling-articles-with-nmf-8c6b2a227a45) to train your model on. That is currently beyond the scope of this project, but will be the next area for exploration.\n",
    "\n",
    "Since we know that we want to find one topic per day to feed into other models, we'll now take our trained model and set it loose on the combined headlines from each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "      <th>Top1</th>\n",
       "      <th>Top2</th>\n",
       "      <th>Top3</th>\n",
       "      <th>Top4</th>\n",
       "      <th>Top5</th>\n",
       "      <th>Top6</th>\n",
       "      <th>Top7</th>\n",
       "      <th>Top8</th>\n",
       "      <th>...</th>\n",
       "      <th>Top19</th>\n",
       "      <th>Top20</th>\n",
       "      <th>Top21</th>\n",
       "      <th>Top22</th>\n",
       "      <th>Top23</th>\n",
       "      <th>Top24</th>\n",
       "      <th>Top25</th>\n",
       "      <th>combined_headlines</th>\n",
       "      <th>daily_topic</th>\n",
       "      <th>daily_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>0</td>\n",
       "      <td>b\"Georgia 'downs two Russian warplanes' as cou...</td>\n",
       "      <td>b'BREAKING: Musharraf to be impeached.'</td>\n",
       "      <td>b'Russia Today: Columns of troops roll into So...</td>\n",
       "      <td>b'Russian tanks are moving towards the capital...</td>\n",
       "      <td>b\"Afghan children raped with 'impunity,' U.N. ...</td>\n",
       "      <td>b'150 Russian tanks have entered South Ossetia...</td>\n",
       "      <td>b\"Breaking: Georgia invades South Ossetia, Rus...</td>\n",
       "      <td>b\"The 'enemy combatent' trials are nothing but...</td>\n",
       "      <td>...</td>\n",
       "      <td>b'This is a busy day:  The European Union has ...</td>\n",
       "      <td>b\"Georgia will withdraw 1,000 soldiers from Ir...</td>\n",
       "      <td>b'Why the Pentagon Thinks Attacking Iran is a ...</td>\n",
       "      <td>b'Caucasus in crisis: Georgia invades South Os...</td>\n",
       "      <td>b'Indian shoe manufactory  - And again in a se...</td>\n",
       "      <td>b'Visitors Suffering from Mental Illnesses Ban...</td>\n",
       "      <td>b\"No Help for Mexico's Kidnapping Surge\"</td>\n",
       "      <td>Georgia 'downs two Russian warplanes' as coun...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006*\"russian\" + 0.006*\"russia\" + 0.004*\"forc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-08-11</td>\n",
       "      <td>1</td>\n",
       "      <td>b'Why wont America and Nato help us? If they w...</td>\n",
       "      <td>b'Bush puts foot down on Georgian conflict'</td>\n",
       "      <td>b\"Jewish Georgian minister: Thanks to Israeli ...</td>\n",
       "      <td>b'Georgian army flees in disarray as Russians ...</td>\n",
       "      <td>b\"Olympic opening ceremony fireworks 'faked'\"</td>\n",
       "      <td>b'What were the Mossad with fraudulent New Zea...</td>\n",
       "      <td>b'Russia angered by Israeli military sale to G...</td>\n",
       "      <td>b'An American citizen living in S.Ossetia blam...</td>\n",
       "      <td>...</td>\n",
       "      <td>b'China to overtake US as largest manufacturer'</td>\n",
       "      <td>b'War in South Ossetia [PICS]'</td>\n",
       "      <td>b'Israeli Physicians Group Condemns State Tort...</td>\n",
       "      <td>b' Russia has just beaten the United States ov...</td>\n",
       "      <td>b'Perhaps *the* question about the Georgia - R...</td>\n",
       "      <td>b'Russia is so much better at war'</td>\n",
       "      <td>b\"So this is what it's come to: trading sex fo...</td>\n",
       "      <td>Why wont America and Nato help us? If they wo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006*\"russian\" + 0.006*\"russia\" + 0.004*\"forc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-08-12</td>\n",
       "      <td>0</td>\n",
       "      <td>b'Remember that adorable 9-year-old who sang a...</td>\n",
       "      <td>b\"Russia 'ends Georgia operation'\"</td>\n",
       "      <td>b'\"If we had no sexual harassment we would hav...</td>\n",
       "      <td>b\"Al-Qa'eda is losing support in Iraq because ...</td>\n",
       "      <td>b'Ceasefire in Georgia: Putin Outmaneuvers the...</td>\n",
       "      <td>b'Why Microsoft and Intel tried to kill the XO...</td>\n",
       "      <td>b'Stratfor: The Russo-Georgian War and the Bal...</td>\n",
       "      <td>b\"I'm Trying to Get a Sense of This Whole Geor...</td>\n",
       "      <td>...</td>\n",
       "      <td>b'Russia, Georgia, and NATO: Cold War Two'</td>\n",
       "      <td>b'Remember that adorable 62-year-old who led y...</td>\n",
       "      <td>b'War in Georgia: The Israeli connection'</td>\n",
       "      <td>b'All signs point to the US encouraging Georgi...</td>\n",
       "      <td>b'Christopher King argues that the US and NATO...</td>\n",
       "      <td>b'America: The New Mexico?'</td>\n",
       "      <td>b\"BBC NEWS | Asia-Pacific | Extinction 'by man...</td>\n",
       "      <td>Remember that adorable 9-year-old who sang at...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006*\"russian\" + 0.006*\"russia\" + 0.004*\"forc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-08-13</td>\n",
       "      <td>0</td>\n",
       "      <td>b' U.S. refuses Israel weapons to attack Iran:...</td>\n",
       "      <td>b\"When the president ordered to attack Tskhinv...</td>\n",
       "      <td>b' Israel clears troops who killed Reuters cam...</td>\n",
       "      <td>b'Britain\\'s policy of being tough on drugs is...</td>\n",
       "      <td>b'Body of 14 year old found in trunk; Latest (...</td>\n",
       "      <td>b'China has moved 10 *million* quake survivors...</td>\n",
       "      <td>b\"Bush announces Operation Get All Up In Russi...</td>\n",
       "      <td>b'Russian forces sink Georgian ships '</td>\n",
       "      <td>...</td>\n",
       "      <td>b'Russian convoy heads into Georgia, violating...</td>\n",
       "      <td>b'Israeli defence minister: US against strike ...</td>\n",
       "      <td>b'Gorbachev: We Had No Choice'</td>\n",
       "      <td>b'Witness: Russian forces head towards Tbilisi...</td>\n",
       "      <td>b' Quarter of Russians blame U.S. for conflict...</td>\n",
       "      <td>b'Georgian president  says US military will ta...</td>\n",
       "      <td>b'2006: Nobel laureate Aleksander Solzhenitsyn...</td>\n",
       "      <td>U.S. refuses Israel weapons to attack Iran: ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006*\"russian\" + 0.006*\"russia\" + 0.004*\"forc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-08-14</td>\n",
       "      <td>1</td>\n",
       "      <td>b'All the experts admit that we should legalis...</td>\n",
       "      <td>b'War in South Osetia - 89 pictures made by a ...</td>\n",
       "      <td>b'Swedish wrestler Ara Abrahamian throws away ...</td>\n",
       "      <td>b'Russia exaggerated the death toll in South O...</td>\n",
       "      <td>b'Missile That Killed 9 Inside Pakistan May Ha...</td>\n",
       "      <td>b\"Rushdie Condemns Random House's Refusal to P...</td>\n",
       "      <td>b'Poland and US agree to missle defense deal. ...</td>\n",
       "      <td>b'Will the Russians conquer Tblisi? Bet on it,...</td>\n",
       "      <td>...</td>\n",
       "      <td>b'\"Non-media\" photos of South Ossetia/Georgia ...</td>\n",
       "      <td>b'Georgian TV reporter shot by Russian sniper ...</td>\n",
       "      <td>b'Saudi Arabia: Mother moves to block child ma...</td>\n",
       "      <td>b'Taliban wages war on humanitarian aid workers'</td>\n",
       "      <td>b'Russia: World  \"can forget about\" Georgia\\'s...</td>\n",
       "      <td>b'Darfur rebels accuse Sudan of mounting major...</td>\n",
       "      <td>b'Philippines : Peace Advocate say Muslims nee...</td>\n",
       "      <td>All the experts admit that we should legalise...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006*\"russian\" + 0.006*\"russia\" + 0.004*\"forc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Label                                               Top1  \\\n",
       "0  2008-08-08      0  b\"Georgia 'downs two Russian warplanes' as cou...   \n",
       "1  2008-08-11      1  b'Why wont America and Nato help us? If they w...   \n",
       "2  2008-08-12      0  b'Remember that adorable 9-year-old who sang a...   \n",
       "3  2008-08-13      0  b' U.S. refuses Israel weapons to attack Iran:...   \n",
       "4  2008-08-14      1  b'All the experts admit that we should legalis...   \n",
       "\n",
       "                                                Top2  \\\n",
       "0            b'BREAKING: Musharraf to be impeached.'   \n",
       "1        b'Bush puts foot down on Georgian conflict'   \n",
       "2                 b\"Russia 'ends Georgia operation'\"   \n",
       "3  b\"When the president ordered to attack Tskhinv...   \n",
       "4  b'War in South Osetia - 89 pictures made by a ...   \n",
       "\n",
       "                                                Top3  \\\n",
       "0  b'Russia Today: Columns of troops roll into So...   \n",
       "1  b\"Jewish Georgian minister: Thanks to Israeli ...   \n",
       "2  b'\"If we had no sexual harassment we would hav...   \n",
       "3  b' Israel clears troops who killed Reuters cam...   \n",
       "4  b'Swedish wrestler Ara Abrahamian throws away ...   \n",
       "\n",
       "                                                Top4  \\\n",
       "0  b'Russian tanks are moving towards the capital...   \n",
       "1  b'Georgian army flees in disarray as Russians ...   \n",
       "2  b\"Al-Qa'eda is losing support in Iraq because ...   \n",
       "3  b'Britain\\'s policy of being tough on drugs is...   \n",
       "4  b'Russia exaggerated the death toll in South O...   \n",
       "\n",
       "                                                Top5  \\\n",
       "0  b\"Afghan children raped with 'impunity,' U.N. ...   \n",
       "1      b\"Olympic opening ceremony fireworks 'faked'\"   \n",
       "2  b'Ceasefire in Georgia: Putin Outmaneuvers the...   \n",
       "3  b'Body of 14 year old found in trunk; Latest (...   \n",
       "4  b'Missile That Killed 9 Inside Pakistan May Ha...   \n",
       "\n",
       "                                                Top6  \\\n",
       "0  b'150 Russian tanks have entered South Ossetia...   \n",
       "1  b'What were the Mossad with fraudulent New Zea...   \n",
       "2  b'Why Microsoft and Intel tried to kill the XO...   \n",
       "3  b'China has moved 10 *million* quake survivors...   \n",
       "4  b\"Rushdie Condemns Random House's Refusal to P...   \n",
       "\n",
       "                                                Top7  \\\n",
       "0  b\"Breaking: Georgia invades South Ossetia, Rus...   \n",
       "1  b'Russia angered by Israeli military sale to G...   \n",
       "2  b'Stratfor: The Russo-Georgian War and the Bal...   \n",
       "3  b\"Bush announces Operation Get All Up In Russi...   \n",
       "4  b'Poland and US agree to missle defense deal. ...   \n",
       "\n",
       "                                                Top8  ...  \\\n",
       "0  b\"The 'enemy combatent' trials are nothing but...  ...   \n",
       "1  b'An American citizen living in S.Ossetia blam...  ...   \n",
       "2  b\"I'm Trying to Get a Sense of This Whole Geor...  ...   \n",
       "3             b'Russian forces sink Georgian ships '  ...   \n",
       "4  b'Will the Russians conquer Tblisi? Bet on it,...  ...   \n",
       "\n",
       "                                               Top19  \\\n",
       "0  b'This is a busy day:  The European Union has ...   \n",
       "1    b'China to overtake US as largest manufacturer'   \n",
       "2         b'Russia, Georgia, and NATO: Cold War Two'   \n",
       "3  b'Russian convoy heads into Georgia, violating...   \n",
       "4  b'\"Non-media\" photos of South Ossetia/Georgia ...   \n",
       "\n",
       "                                               Top20  \\\n",
       "0  b\"Georgia will withdraw 1,000 soldiers from Ir...   \n",
       "1                     b'War in South Ossetia [PICS]'   \n",
       "2  b'Remember that adorable 62-year-old who led y...   \n",
       "3  b'Israeli defence minister: US against strike ...   \n",
       "4  b'Georgian TV reporter shot by Russian sniper ...   \n",
       "\n",
       "                                               Top21  \\\n",
       "0  b'Why the Pentagon Thinks Attacking Iran is a ...   \n",
       "1  b'Israeli Physicians Group Condemns State Tort...   \n",
       "2          b'War in Georgia: The Israeli connection'   \n",
       "3                     b'Gorbachev: We Had No Choice'   \n",
       "4  b'Saudi Arabia: Mother moves to block child ma...   \n",
       "\n",
       "                                               Top22  \\\n",
       "0  b'Caucasus in crisis: Georgia invades South Os...   \n",
       "1  b' Russia has just beaten the United States ov...   \n",
       "2  b'All signs point to the US encouraging Georgi...   \n",
       "3  b'Witness: Russian forces head towards Tbilisi...   \n",
       "4   b'Taliban wages war on humanitarian aid workers'   \n",
       "\n",
       "                                               Top23  \\\n",
       "0  b'Indian shoe manufactory  - And again in a se...   \n",
       "1  b'Perhaps *the* question about the Georgia - R...   \n",
       "2  b'Christopher King argues that the US and NATO...   \n",
       "3  b' Quarter of Russians blame U.S. for conflict...   \n",
       "4  b'Russia: World  \"can forget about\" Georgia\\'s...   \n",
       "\n",
       "                                               Top24  \\\n",
       "0  b'Visitors Suffering from Mental Illnesses Ban...   \n",
       "1                 b'Russia is so much better at war'   \n",
       "2                        b'America: The New Mexico?'   \n",
       "3  b'Georgian president  says US military will ta...   \n",
       "4  b'Darfur rebels accuse Sudan of mounting major...   \n",
       "\n",
       "                                               Top25  \\\n",
       "0           b\"No Help for Mexico's Kidnapping Surge\"   \n",
       "1  b\"So this is what it's come to: trading sex fo...   \n",
       "2  b\"BBC NEWS | Asia-Pacific | Extinction 'by man...   \n",
       "3  b'2006: Nobel laureate Aleksander Solzhenitsyn...   \n",
       "4  b'Philippines : Peace Advocate say Muslims nee...   \n",
       "\n",
       "                                  combined_headlines daily_topic  \\\n",
       "0   Georgia 'downs two Russian warplanes' as coun...           1   \n",
       "1   Why wont America and Nato help us? If they wo...           1   \n",
       "2   Remember that adorable 9-year-old who sang at...           1   \n",
       "3    U.S. refuses Israel weapons to attack Iran: ...           1   \n",
       "4   All the experts admit that we should legalise...           1   \n",
       "\n",
       "                                         daily_words  \n",
       "0  0.006*\"russian\" + 0.006*\"russia\" + 0.004*\"forc...  \n",
       "1  0.006*\"russian\" + 0.006*\"russia\" + 0.004*\"forc...  \n",
       "2  0.006*\"russian\" + 0.006*\"russia\" + 0.004*\"forc...  \n",
       "3  0.006*\"russian\" + 0.006*\"russia\" + 0.004*\"forc...  \n",
       "4  0.006*\"russian\" + 0.006*\"russia\" + 0.004*\"forc...  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_topic = pd.read_csv(\"../Data/Combined_News_DJIA_single_topic.csv\")\n",
    "single_topic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and tokenize headlines \n",
    "single_topic['tokenized'] = single_topic['combined_headlines'].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the headlines using TF-IDF to create features to train our model on\n",
    "dictionary = gensim.corpora.Dictionary(single_topic['tokenized'])\n",
    "\n",
    "'''\n",
    "Filter out irrelevant words:\n",
    "Keep tokens that appear in at least 15 documents\n",
    "Keep only the 100,000 most frequent tokens\n",
    "'''\n",
    "dictionary.filter_extremes(no_below=15, keep_n=100000)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    min_df=3, # ignore words that appear in less than 3 articles\n",
    "    max_df=0.85, # ignore words that appear in more than 85% of articles\n",
    "    max_features=5000, # limit the number of important words to 5,000\n",
    "    ngram_range=(1, 2), # look for both words and two-word phrases\n",
    "    preprocessor=' '.join # join the tokenized words instead of creating a list\n",
    ")\n",
    "\n",
    "# Helped by https://stackabuse.com/python-for-nlp-topic-modeling/\n",
    "doctermmatrix = tfidf_vectorizer.fit_transform(single_topic['tokenized'])\n",
    "\n",
    "topic_values = model.transform(doctermmatrix)\n",
    "single_topic['nmf_topic'] = topic_values.argmax(axis=1)\n",
    "single_topic.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create human readable topic word lists to append to df\n",
    "nmf_topics = []\n",
    "\n",
    "for i,topic in enumerate(model.components_):\n",
    "    nmf_topics.append([tfidf_vectorizer.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
    "    \n",
    "def get_topic_list(topic):\n",
    "    return nmf_topics[topic]\n",
    "    \n",
    "single_topic['nmf_topic_readable'] = single_topic['nmf_topic'].apply(get_topic_list)\n",
    "\n",
    "single_topic.rename(columns={\n",
    "    'daily_topic': 'lda_topic',\n",
    "    'daily_words': 'lda_topic_readable'\n",
    "}, inplace=True)\n",
    "\n",
    "single_topic.drop(labels=['tokenized'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save updated data\n",
    "single_topic.to_csv(\"../Data/Combined_News_DJIA_single_topic.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
